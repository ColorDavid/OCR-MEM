#!/bin/bash
# ==============================================================================
# MEMModel Adapter è®­ç»ƒå¯åŠ¨è„šæœ¬
# ==============================================================================
#
# æœ¬è„šæœ¬ç”¨äºå¤šå¡åˆ†å¸ƒå¼è®­ç»ƒï¼Œä½¿ç”¨ DeepSpeed æˆ– torchrun å¯åŠ¨ã€‚
#
# ã€ä½¿ç”¨æ–¹æ³•ã€‘
#     1. èµ‹äºˆæ‰§è¡Œæƒé™ï¼šchmod +x run_training.sh
#     2. è¿è¡Œè„šæœ¬ï¼š./run_training.sh
#
# ã€è¿è¡Œä½ç½®ã€‘
#     å¿…é¡»åœ¨ OCR-MEM ç›®å½•ä¸‹è¿è¡Œ
#
# ã€ç¯å¢ƒè¦æ±‚ã€‘
#     - Python 3.8+
#     - PyTorch 2.0+
#     - transformers 4.35+
#     - deepspeed 0.12+
#     - wandb
#
# ==============================================================================

# è®¾ç½®å·¥ä½œç›®å½•ä¸ºè„šæœ¬æ‰€åœ¨ç›®å½•
cd "$(dirname "$0")"

echo "============================================================"
echo "MEMModel Adapter Training Script"
echo "============================================================"
echo "å·¥ä½œç›®å½•: $(pwd)"
echo "Python: $(which python)"
echo "PyTorch: $(python -c 'import torch; print(torch.__version__)')"
echo "CUDA å¯ç”¨: $(python -c 'import torch; print(torch.cuda.is_available())')"
echo "GPU æ•°é‡: $(python -c 'import torch; print(torch.cuda.device_count())')"
echo "============================================================"


# ==============================================================================
# é…ç½®åŒºåŸŸ - è¯·æ ¹æ®æ‚¨çš„ç¯å¢ƒä¿®æ”¹
# ==============================================================================

# -------------------- WandB é…ç½® --------------------
# WandB API Keyï¼ˆç”¨äºæ—¥å¿—è®°å½•å’Œå¯è§†åŒ–ï¼‰
export WANDB_API_KEY="c8769e5bbc8fd36df4155b757331cd139e0fc327"

# WandB é¡¹ç›®åç§°
export WANDB_PROJECT="OCR-MEM"

# WandB å®éªŒåç§°ï¼ˆå¯é€‰ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰
export WANDB_RUN_NAME="mem_adapter_training"

# WandB æ¨¡å¼ï¼šonlineï¼ˆå®æ—¶åŒæ­¥ï¼‰ã€offlineï¼ˆç¦»çº¿ä¿å­˜ï¼‰ã€disabledï¼ˆç¦ç”¨ï¼‰
export WANDB_MODE="online"

# -------------------- æ¨¡å‹è·¯å¾„ï¼ˆæœ¬åœ°è·¯å¾„ï¼‰--------------------
# åŸºç¡€è¯­è¨€æ¨¡å‹è·¯å¾„
export BASE_MODEL_PATH="/mmu_nlp_ssd/tangjingyi03/OCR-MEM/model/Qwen/Qwen3-8B"

# OCR ç¼–ç å™¨è·¯å¾„
export OCR_MODEL_PATH="/mmu_nlp_ssd/tangjingyi03/models/deepseek-ai/DeepSeek-OCR"

# -------------------- æ•°æ®è·¯å¾„ --------------------
# è®­ç»ƒæ•°æ®
export TRAIN_DATA="/mmu_nlp_ssd/tangjingyi03/OCR-MEM/data/train_data_of_merged_total_66025_rmtestset_first_100.jsonl"

# éªŒè¯æ•°æ®ï¼ˆå¯é€‰ï¼‰
export EVAL_DATA="/mmu_nlp_ssd/tangjingyi03/OCR-MEM/data/train_data_of_merged_total_66025_rmtestset_first_100.jsonl"

# -------------------- è¾“å‡ºç›®å½• --------------------
export OUTPUT_DIR="./adapter_checkpoints"

# -------------------- è®­ç»ƒè¶…å‚æ•° --------------------
export NUM_EPOCHS=2
export BATCH_SIZE=2
export GRADIENT_ACCUMULATION=8
export LEARNING_RATE=2e-4

# -------------------- GPU é…ç½® --------------------
# æŒ‡å®šä½¿ç”¨çš„ GPUï¼ˆä¾‹å¦‚ "0,1,2,3"ï¼‰
export CUDA_VISIBLE_DEVICES="0,1,2,3"

# GPU æ•°é‡ï¼ˆä¸ CUDA_VISIBLE_DEVICES ä¸­çš„æ•°é‡ä¸€è‡´ï¼‰
export NUM_GPUS=4

# åˆ†å¸ƒå¼è®­ç»ƒç«¯å£ï¼ˆå¦‚æœ‰å†²çªè¯·ä¿®æ”¹ï¼‰
export MASTER_PORT=29500


# ==============================================================================
# é€‰æ‹©è®­ç»ƒæ¨¡å¼
# ==============================================================================
# å¯é€‰å€¼ï¼š
#   deepspeed - DeepSpeed å¤šå¡è®­ç»ƒï¼ˆæ¨èï¼‰
#   torchrun  - PyTorch åŸç”Ÿåˆ†å¸ƒå¼è®­ç»ƒ

TRAINING_MODE="deepspeed"


# ==============================================================================
# è®­ç»ƒå¯åŠ¨
# ==============================================================================

case $TRAINING_MODE in

    # --------------------------------------------------------------------------
    # DeepSpeed å¤šå¡è®­ç»ƒï¼ˆæ¨èï¼‰
    # --------------------------------------------------------------------------
    "deepspeed")
        echo ""
        echo "å¯åŠ¨ DeepSpeed å¤šå¡è®­ç»ƒ..."
        echo "GPU: $CUDA_VISIBLE_DEVICES"
        echo "GPU æ•°é‡: $NUM_GPUS"
        echo "WandB é¡¹ç›®: $WANDB_PROJECT"
        echo ""
        
        # DeepSpeed å¯åŠ¨å‘½ä»¤
        # --num_gpus: GPU æ•°é‡
        # --master_port: ä¸»èŠ‚ç‚¹ç«¯å£ï¼ˆå¦‚æœ‰å†²çªè¯·ä¿®æ”¹ï¼‰
        deepspeed --num_gpus=$NUM_GPUS \
            --master_port=$MASTER_PORT \
            run_training.py \
            --base_model_path "$BASE_MODEL_PATH" \
            --ocr_model_path "$OCR_MODEL_PATH" \
            --train_data "$TRAIN_DATA" \
            --eval_data "$EVAL_DATA" \
            --output_dir "$OUTPUT_DIR" \
            --num_epochs $NUM_EPOCHS \
            --batch_size $BATCH_SIZE \
            --gradient_accumulation $GRADIENT_ACCUMULATION \
            --learning_rate $LEARNING_RATE \
            --wandb_project "$WANDB_PROJECT" \
            --wandb_run_name "$WANDB_RUN_NAME"
        ;;

    # --------------------------------------------------------------------------
    # PyTorch åŸç”Ÿåˆ†å¸ƒå¼è®­ç»ƒ
    # --------------------------------------------------------------------------
    "torchrun")
        echo ""
        echo "å¯åŠ¨ torchrun åˆ†å¸ƒå¼è®­ç»ƒ..."
        echo "GPU: $CUDA_VISIBLE_DEVICES"
        echo "GPU æ•°é‡: $NUM_GPUS"
        echo "WandB é¡¹ç›®: $WANDB_PROJECT"
        echo ""
        
        # torchrun å¯åŠ¨å‘½ä»¤
        # --nproc_per_node: æ¯ä¸ªèŠ‚ç‚¹çš„è¿›ç¨‹æ•°ï¼ˆGPU æ•°é‡ï¼‰
        # --master_port: ä¸»èŠ‚ç‚¹ç«¯å£
        torchrun --nproc_per_node=$NUM_GPUS \
            --master_port=$MASTER_PORT \
            run_training.py \
            --base_model_path "$BASE_MODEL_PATH" \
            --ocr_model_path "$OCR_MODEL_PATH" \
            --train_data "$TRAIN_DATA" \
            --eval_data "$EVAL_DATA" \
            --output_dir "$OUTPUT_DIR" \
            --num_epochs $NUM_EPOCHS \
            --batch_size $BATCH_SIZE \
            --gradient_accumulation $GRADIENT_ACCUMULATION \
            --learning_rate $LEARNING_RATE \
            --wandb_project "$WANDB_PROJECT" \
            --wandb_run_name "$WANDB_RUN_NAME"
        ;;

    *)
        echo "é”™è¯¯: æœªçŸ¥çš„è®­ç»ƒæ¨¡å¼ '$TRAINING_MODE'"
        echo "å¯é€‰å€¼: deepspeed, torchrun"
        exit 1
        ;;
esac


# ==============================================================================
# è®­ç»ƒå®Œæˆ
# ==============================================================================

if [ $? -eq 0 ]; then
    echo ""
    echo "============================================================"
    echo "ğŸ‰ è®­ç»ƒå®Œæˆï¼"
    echo "============================================================"
    echo "æ£€æŸ¥ç‚¹ä¿å­˜åœ¨: $OUTPUT_DIR"
    echo "æœ€ç»ˆé€‚é…å™¨: $OUTPUT_DIR/final_adapter"
    echo "============================================================"
else
    echo ""
    echo "============================================================"
    echo "âŒ è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—"
    echo "============================================================"
    exit 1
fi
