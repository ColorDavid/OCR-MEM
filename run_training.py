#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
MEMModel Adapter è®­ç»ƒè„šæœ¬
================================================================================

æœ¬è„šæœ¬ç”¨äºå¯åŠ¨ MEMModel æŠ•å½±é€‚é…å™¨çš„è®­ç»ƒã€‚

ã€è¿è¡Œä½ç½®ã€‘
    å¿…é¡»åœ¨ OCR-MEM ç›®å½•ä¸‹è¿è¡Œï¼š
    cd /path/to/OCR-MEM
    
ã€è¿è¡Œæ–¹å¼ã€‘
    1. å•æœºå•å¡è®­ç»ƒï¼š
        python run_training.py
    
    2. å•æœºå¤šå¡è®­ç»ƒï¼ˆæ¨èä½¿ç”¨ DeepSpeedï¼‰ï¼š
        deepspeed --num_gpus=4 run_training.py
    
    3. ä½¿ç”¨ torchrun å¤šå¡è®­ç»ƒï¼š
        torchrun --nproc_per_node=4 run_training.py
    
    4. ä½¿ç”¨æä¾›çš„ shell è„šæœ¬ï¼š
        bash run_training.sh

ã€ç›®å½•ç»“æ„è¦æ±‚ã€‘
    OCR-MEM/
    â”œâ”€â”€ run_training.py          # æœ¬è„šæœ¬
    â”œâ”€â”€ run_training.sh          # Shell å¯åŠ¨è„šæœ¬
    â”œâ”€â”€ ds_config.json           # DeepSpeed é…ç½®ï¼ˆè‡ªåŠ¨ç”Ÿæˆæˆ–æ‰‹åŠ¨æŒ‡å®šï¼‰
    â”œâ”€â”€ mem_adapter_only.py      # MEMModel å®šä¹‰
    â”œâ”€â”€ trainer/
    â”‚   â””â”€â”€ adapter_only_trainer.py
    â”œâ”€â”€ utils/
    â”‚   â””â”€â”€ data.py
    â”œâ”€â”€ data/                    # è®­ç»ƒæ•°æ®ç›®å½•
    â”‚   â”œâ”€â”€ train.jsonl
    â”‚   â””â”€â”€ eval.jsonl
    â”œâ”€â”€ models/                  # æœ¬åœ°æ¨¡å‹ç›®å½•
    â”‚   â”œâ”€â”€ qwen2.5-1.5b/        # åŸºç¡€è¯­è¨€æ¨¡å‹
    â”‚   â””â”€â”€ deepseek-ocr/        # OCR ç¼–ç å™¨
    â””â”€â”€ output/                  # è¾“å‡ºç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
        â””â”€â”€ adapter_checkpoints/

ã€é…ç½®è¯´æ˜ã€‘
    è¯·æ ¹æ®æ‚¨çš„å®é™…ç¯å¢ƒä¿®æ”¹ä»¥ä¸‹é…ç½®ï¼š
    1. MODEL_CONFIG: æ¨¡å‹ç›¸å…³è·¯å¾„
    2. DATA_CONFIG: æ•°æ®é›†è·¯å¾„
    3. TRAINING_CONFIG: è®­ç»ƒè¶…å‚æ•°
    4. DEEPSPEED_CONFIG: DeepSpeed é…ç½®ï¼ˆå¯é€‰ï¼‰

ä½œè€…ï¼šOCR-MEM Team
================================================================================
"""

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import json
import argparse
from pathlib import Path
from functools import partial
from dataclasses import dataclass, field
from typing import Optional

import torch
import torch.distributed as dist

try:
    import wandb
    WANDB_AVAILABLE = True
except ImportError:
    WANDB_AVAILABLE = False
    print("è­¦å‘Š: wandb æœªå®‰è£…ï¼Œå°†ç¦ç”¨ wandb æ—¥å¿—")

from transformers import TrainingArguments

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.absolute()
sys.path.insert(0, str(PROJECT_ROOT))

from mem_adapter_only import MEMModel, MEMConfig
from trainer.adapter_only_trainer import AdapterOnlyTrainer, AdapterTrainingArguments
from utils.data import MultiTurnConversationDataset, collate_fn


# ============================================================================
# é…ç½®åŒºåŸŸ - è¯·æ ¹æ®æ‚¨çš„ç¯å¢ƒä¿®æ”¹
# ============================================================================

# -------------------- æ¨¡å‹é…ç½® --------------------
# æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼Œè€Œé HuggingFace ID
MODEL_CONFIG = {
    # åŸºç¡€è¯­è¨€æ¨¡å‹çš„æœ¬åœ°è·¯å¾„
    # ä¾‹å¦‚ï¼š"/data/models/Qwen2.5-1.5B-Instruct" æˆ– "./models/qwen2.5-1.5b"
    "base_model_path": "./models/qwen2.5-1.5b-instruct",
    
    # OCR è§†è§‰ç¼–ç å™¨çš„æœ¬åœ°è·¯å¾„
    # ä¾‹å¦‚ï¼š"/data/models/DeepSeek-OCR" æˆ– "./models/deepseek-ocr"
    "ocr_model_path": "./models/deepseek-ocr",
    
    # è§†è§‰ç¼–ç å™¨è¾“å‡ºçš„åµŒå…¥ç»´åº¦ï¼ˆéœ€ä¸ OCR æ¨¡å‹åŒ¹é…ï¼‰
    "vision_embedding_size": 512,
    
    # è§¦å‘è§†è§‰å‹ç¼©çš„ä¸Šä¸‹æ–‡é•¿åº¦é˜ˆå€¼
    "context_threshold": 2048,
}

# -------------------- æ•°æ®é…ç½® --------------------
DATA_CONFIG = {
    # è®­ç»ƒæ•°æ® JSONL æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„
    "train_data_path": "./data/train.jsonl",
    
    # éªŒè¯æ•°æ® JSONL æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„ï¼ˆå¯é€‰ï¼Œè®¾ä¸º None è·³è¿‡éªŒè¯ï¼‰
    "eval_data_path": "./data/eval.jsonl",
    
    # æœ€å¤§åºåˆ—é•¿åº¦
    "max_seq_length": 2048,
}

# -------------------- è®­ç»ƒé…ç½® --------------------
TRAINING_CONFIG = {
    # è¾“å‡ºç›®å½•
    "output_dir": "./output/adapter_checkpoints",
    
    # å®éªŒåç§°ï¼ˆç”¨äºæ—¥å¿—å’Œ WandBï¼‰
    "run_name": "mem_adapter_training",
    
    # WandB é¡¹ç›®åç§°
    "wandb_project": "OCR-MEM",
    
    # è®­ç»ƒè½®æ•°
    "num_train_epochs": 3,
    
    # æ¯ä¸ª GPU çš„è®­ç»ƒ batch size
    "per_device_train_batch_size": 2,
    
    # æ¯ä¸ª GPU çš„éªŒè¯ batch size
    "per_device_eval_batch_size": 4,
    
    # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆæœ‰æ•ˆ batch size = per_device * accumulation * num_gpusï¼‰
    "gradient_accumulation_steps": 8,
    
    # å­¦ä¹ ç‡
    "learning_rate": 2e-4,
    
    # Warmup æ¯”ä¾‹
    "warmup_ratio": 0.1,
    
    # æƒé‡è¡°å‡
    "weight_decay": 0.01,
    
    # æ¢¯åº¦è£å‰ª
    "max_grad_norm": 1.0,
    
    # è¯„ä¼°ç­–ç•¥
    "eval_strategy": "steps",
    "eval_steps": 200,
    
    # ä¿å­˜ç­–ç•¥
    "save_strategy": "steps",
    "save_steps": 200,
    "save_total_limit": 3,
    
    # æ—¥å¿—ç­–ç•¥
    "logging_steps": 10,
    
    # æ•°æ®åŠ è½½å™¨é…ç½®
    "dataloader_num_workers": 4,
    
    # éšæœºç§å­
    "seed": 42,
}

# -------------------- DeepSpeed é…ç½® --------------------
# å¦‚æœè®¾ä¸º Noneï¼Œå°†è‡ªåŠ¨ç”Ÿæˆé…ç½®
# å¦‚æœè®¾ä¸ºè·¯å¾„å­—ç¬¦ä¸²ï¼Œå°†ä½¿ç”¨æŒ‡å®šçš„é…ç½®æ–‡ä»¶
DEEPSPEED_CONFIG_PATH = None  # ä¾‹å¦‚: "./ds_config.json"


# ============================================================================
# DeepSpeed é…ç½®ç”Ÿæˆ
# ============================================================================

def create_deepspeed_config(
    output_dir: str,
    per_device_batch_size: int = 2,
    gradient_accumulation_steps: int = 8,
    max_grad_norm: float = 1.0,
    logging_steps: int = 10,
) -> str:
    """
    åˆ›å»º DeepSpeed ZeRO-2 é…ç½®æ–‡ä»¶
    
    ã€DeepSpeed ZeRO ä¼˜åŒ–çº§åˆ«è¯´æ˜ã€‘
    - ZeRO Stage 0: æ— ä¼˜åŒ–ï¼ŒåŸºå‡†
    - ZeRO Stage 1: ä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡
    - ZeRO Stage 2: ä¼˜åŒ–å™¨çŠ¶æ€ + æ¢¯åº¦åˆ†ç‰‡ï¼ˆæ¨èç”¨äºå¾®è°ƒï¼‰
    - ZeRO Stage 3: ä¼˜åŒ–å™¨çŠ¶æ€ + æ¢¯åº¦ + æ¨¡å‹å‚æ•°åˆ†ç‰‡ï¼ˆæœ€çœæ˜¾å­˜ï¼Œä½†è¾ƒæ…¢ï¼‰
    
    æœ¬é…ç½®ä½¿ç”¨ ZeRO Stage 2 + CPU Offloadingï¼Œé€‚åˆï¼š
    - å•æœºå¤šå¡è®­ç»ƒ
    - æ˜¾å­˜å—é™ç¯å¢ƒï¼ˆå¦‚ 24GB æ˜¾å¡è®­ç»ƒ 7B æ¨¡å‹ï¼‰
    - é€‚é…å™¨å¾®è°ƒï¼ˆåªè®­ç»ƒå°‘é‡å‚æ•°ï¼‰
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        per_device_batch_size: æ¯ä¸ª GPU çš„ batch size
        gradient_accumulation_steps: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
        max_grad_norm: æ¢¯åº¦è£å‰ªé˜ˆå€¼
        logging_steps: æ—¥å¿—è¾“å‡ºé—´éš”
    
    Returns:
        é…ç½®æ–‡ä»¶è·¯å¾„
    """
    
    # è·å– world sizeï¼ˆGPU æ•°é‡ï¼‰
    if dist.is_available() and dist.is_initialized():
        world_size = dist.get_world_size()
    else:
        # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        world_size = int(os.environ.get("WORLD_SIZE", 1))
    
    # è®¡ç®—å…¨å±€ batch size
    train_batch_size = per_device_batch_size * gradient_accumulation_steps * world_size

    # åŸå§‹ds_configè®¾ç½®    
    # # DeepSpeed é…ç½®
    # ds_config = {
    #     # ============================================================
    #     # æ‰¹æ¬¡é…ç½®
    #     # ============================================================
    #     # å…¨å±€ batch size = per_device * accumulation * world_size
    #     "train_batch_size": train_batch_size,
        
    #     # æ¯ä¸ª GPU æ¯æ¬¡å‰å‘ä¼ æ’­çš„ batch size
    #     "train_micro_batch_size_per_gpu": per_device_batch_size,
        
    #     # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
    #     "gradient_accumulation_steps": gradient_accumulation_steps,
        
    #     # ============================================================
    #     # ç²¾åº¦é…ç½®
    #     # ============================================================
    #     # ä½¿ç”¨ BFloat16 æ··åˆç²¾åº¦ï¼ˆæ¯” FP16 æ›´ç¨³å®šï¼ŒA100/H100 æ¨èï¼‰
    #     "bf16": {
    #         "enabled": True
    #     },
        
    #     # ç¦ç”¨ FP16ï¼ˆä¸ BF16 äº’æ–¥ï¼‰
    #     "fp16": {
    #         "enabled": False
    #     },
        
    #     # ============================================================
    #     # ZeRO ä¼˜åŒ–é…ç½®
    #     # ============================================================
    #     "zero_optimization": {
    #         # ZeRO Stage 2: ä¼˜åŒ–å™¨çŠ¶æ€ + æ¢¯åº¦åˆ†ç‰‡
    #         # æ˜¾å­˜èŠ‚çœçº¦ 50-60%ï¼Œé€šä¿¡å¼€é”€é€‚ä¸­
    #         "stage": 2,
            
    #         # å°†ä¼˜åŒ–å™¨çŠ¶æ€ offload åˆ° CPU
    #         # Adam ä¼˜åŒ–å™¨çš„ momentum å’Œ variance ä¼šå ç”¨å¤§é‡æ˜¾å­˜
    #         # Offload åå¯èŠ‚çœçº¦ 2x æ¨¡å‹å¤§å°çš„æ˜¾å­˜
    #         "offload_optimizer": {
    #             "device": "cpu",           # ç›®æ ‡è®¾å¤‡
    #             "pin_memory": True,        # ä½¿ç”¨é”é¡µå†…å­˜åŠ é€Ÿä¼ è¾“
    #             "buffer_count": 4,         # ç¼“å†²åŒºæ•°é‡
    #             "fast_init": False         # å¿«é€Ÿåˆå§‹åŒ–ï¼ˆå¯èƒ½ä¸ç¨³å®šï¼‰
    #         },
            
    #         # æ˜¯å¦ offload å‚æ•°åˆ° CPUï¼ˆStage 3 æ—¶ç”Ÿæ•ˆï¼‰
    #         # Stage 2 æ—¶æ­¤é€‰é¡¹æ— æ•ˆ
    #         # "offload_param": {
    #         #     "device": "cpu",
    #         #     "pin_memory": True
    #         # },
            
    #         # AllGather ä¼˜åŒ–
    #         "allgather_partitions": True,
    #         "allgather_bucket_size": 5e8,
            
    #         # Reduce-Scatter ä¼˜åŒ–
    #         "reduce_scatter": True,
    #         "reduce_bucket_size": 5e8,
            
    #         # é€šä¿¡ä¸è®¡ç®—é‡å 
    #         "overlap_comm": True,
            
    #         # ä½¿ç”¨è¿ç»­æ¢¯åº¦å­˜å‚¨ï¼ˆå‡å°‘å†…å­˜ç¢ç‰‡ï¼‰
    #         "contiguous_gradients": True,
            
    #         # å­ç»„å¤§å°ï¼ˆå½±å“é€šä¿¡æ•ˆç‡ï¼‰
    #         # "sub_group_size": 1e9,
            
    #         # æ˜¯å¦åœ¨ç¬¬ä¸€æ­¥åå‡å°‘ bucket å¤§å°
    #         "reduce_bucket_size": 1280*1280*2,#"auto",
            
    #         # é˜¶æ®µ 3 ç›¸å…³é€‰é¡¹ï¼ˆæ­¤å¤„ä¸ä½¿ç”¨ï¼‰
    #         # "stage3_prefetch_bucket_size": "auto",
    #         # "stage3_param_persistence_threshold": "auto",
    #         # "stage3_max_live_parameters": 1e9,
    #         # "stage3_max_reuse_distance": 1e9,
    #         # "stage3_gather_16bit_weights_on_model_save": True,
    #     },
        
    #     # ============================================================
    #     # æ¢¯åº¦é…ç½®
    #     # ============================================================
    #     # æ¢¯åº¦è£å‰ª
    #     "gradient_clipping": max_grad_norm,
        
    #     # ============================================================
    #     # æ¿€æ´»æ£€æŸ¥ç‚¹ï¼ˆèŠ‚çœæ˜¾å­˜ï¼Œä½†å¢åŠ è®¡ç®—æ—¶é—´ï¼‰
    #     # ============================================================
    #     # æ³¨æ„ï¼šè¿™é‡Œä¸å¯ç”¨ï¼Œå› ä¸ºæˆ‘ä»¬åªè®­ç»ƒ adapter
    #     # å¦‚æœéœ€è¦ï¼Œå¯ä»¥åœ¨æ¨¡å‹ä¸­æ‰‹åŠ¨å¯ç”¨ gradient_checkpointing
    #     # "activation_checkpointing": {
    #     #     "partition_activations": True,
    #     #     "cpu_checkpointing": True,
    #     #     "contiguous_memory_optimization": True,
    #     #     "number_checkpoints": None,
    #     #     "synchronize_checkpoint_boundary": False,
    #     #     "profile": False
    #     # },
        
    #     # ============================================================
    #     # æ—¥å¿—ä¸è°ƒè¯•
    #     # ============================================================
    #     "steps_per_print": logging_steps,
    #     "wall_clock_breakdown": False,
        
    #     # ç¦ç”¨ä¸éœ€è¦çš„åŠŸèƒ½
    #     "dump_state": False,
    # }
    ds_config = {
        "train_batch_size": 128,
        "train_micro_batch_size_per_gpu": 2,
        "gradient_accumulation_steps": 8,

        "optimizer": {
            "type": "AdamW",
            "params": {
                "lr": 2e-4,
                "betas": [0.9, 0.999],
                "eps": 1e-8,
                "weight_decay": 0.01
            }
        },

        "scheduler": {
            "type": "WarmupLR",
            "params": {
                "warmup_min_lr": 0,
                "warmup_max_lr": 2e-4,
                "warmup_num_steps": "auto"  # å…³é”®ä¿®æ”¹
            }
        },

        "zero_optimization": {
            "stage": 2,
            "contiguous_gradients": True,
            "overlap_comm": True,
            "reduce_scatter": True,
            "allgather_partitions": True,
            "allgather_bucket_size": 5e8,
            "reduce_bucket_size": 5e8,
        },

        "fp16": {"enabled": False},
        "bf16": {"enabled": True},

        "gradient_clipping": 1.0,
        "steps_per_print": 10,
        "wall_clock_breakdown": False,
    }

    # ä¿å­˜é…ç½®æ–‡ä»¶
    config_path = os.path.join(output_dir, "ds_config_auto.json")
    os.makedirs(output_dir, exist_ok=True)
    
    with open(config_path, "w", encoding="utf-8") as f:
        json.dump(ds_config, f, indent=2, ensure_ascii=False)
    
    print(f"\n{'='*60}")
    print("DeepSpeed é…ç½®å·²ç”Ÿæˆ")
    print(f"{'='*60}")
    print(f"é…ç½®æ–‡ä»¶: {config_path}")
    print(f"ZeRO Stage: 2")
    print(f"CPU Offloading: ä¼˜åŒ–å™¨çŠ¶æ€")
    print(f"ç²¾åº¦: BFloat16")
    print(f"å…¨å±€ Batch Size: {train_batch_size}")
    print(f"æ¯ GPU Batch Size: {per_device_batch_size}")
    print(f"æ¢¯åº¦ç´¯ç§¯: {gradient_accumulation_steps}")
    print(f"World Size: {world_size}")
    print(f"{'='*60}\n")
    
    return config_path


# ============================================================================
# ä¸»è®­ç»ƒå‡½æ•°
# ============================================================================

def main():
    """
    ä¸»è®­ç»ƒå…¥å£
    
    æ‰§è¡Œæµç¨‹ï¼š
    1. è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆå¯è¦†ç›–é…ç½®ï¼‰
    2. éªŒè¯è·¯å¾„å’Œç¯å¢ƒ
    3. åˆ›å»º/åŠ è½½ DeepSpeed é…ç½®
    4. åˆå§‹åŒ–æ¨¡å‹
    5. åŠ è½½æ•°æ®é›†
    6. åˆå§‹åŒ–è®­ç»ƒå™¨
    7. æ‰§è¡Œè®­ç»ƒ
    8. ä¿å­˜æœ€ç»ˆæ¨¡å‹
    """
    
    # ==================== è§£æå‘½ä»¤è¡Œå‚æ•° ====================
    parser = argparse.ArgumentParser(description="MEMModel Adapter Training Script")
    
    # æ¨¡å‹è·¯å¾„å‚æ•°ï¼ˆå¯è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ï¼‰
    parser.add_argument(
        "--base_model_path", 
        type=str, 
        default=None,
        help="åŸºç¡€è¯­è¨€æ¨¡å‹çš„æœ¬åœ°è·¯å¾„"
    )
    parser.add_argument(
        "--ocr_model_path", 
        type=str, 
        default=None,
        help="OCR ç¼–ç å™¨çš„æœ¬åœ°è·¯å¾„"
    )
    
    # æ•°æ®è·¯å¾„å‚æ•°
    parser.add_argument(
        "--train_data", 
        type=str, 
        default=None,
        help="è®­ç»ƒæ•°æ® JSONL æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--eval_data", 
        type=str, 
        default=None,
        help="éªŒè¯æ•°æ® JSONL æ–‡ä»¶è·¯å¾„"
    )
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument(
        "--output_dir", 
        type=str, 
        default=None,
        help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--num_epochs", 
        type=int, 
        default=None,
        help="è®­ç»ƒè½®æ•°"
    )
    parser.add_argument(
        "--batch_size", 
        type=int, 
        default=None,
        help="æ¯ GPU è®­ç»ƒ batch size"
    )
    parser.add_argument(
        "--learning_rate", 
        type=float, 
        default=None,
        help="å­¦ä¹ ç‡"
    )
    parser.add_argument(
        "--gradient_accumulation", 
        type=int, 
        default=None,
        help="æ¢¯åº¦ç´¯ç§¯æ­¥æ•°"
    )
    
    # DeepSpeed é…ç½®
    parser.add_argument(
        "--deepspeed", 
        type=str, 
        default=None,
        help="DeepSpeed é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ä¸æŒ‡å®šåˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰"
    )
    parser.add_argument(
        "--local_rank", 
        type=int, 
        default=-1,
        help="åˆ†å¸ƒå¼è®­ç»ƒçš„ local rankï¼ˆç”± DeepSpeed è‡ªåŠ¨è®¾ç½®ï¼‰"
    )
    
    # WandB é…ç½®
    parser.add_argument(
        "--wandb_project", 
        type=str, 
        default=None,
        help="WandB é¡¹ç›®åç§°"
    )
    parser.add_argument(
        "--wandb_run_name", 
        type=str, 
        default=None,
        help="WandB å®éªŒåç§°"
    )
    parser.add_argument(
        "--disable_wandb", 
        action="store_true",
        help="ç¦ç”¨ WandB æ—¥å¿—"
    )
    
    args = parser.parse_args()
    
    # ==================== åˆå¹¶é…ç½® ====================
    # å‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆçº§é«˜äºé…ç½®æ–‡ä»¶
    
    base_model_path = args.base_model_path or MODEL_CONFIG["base_model_path"]
    ocr_model_path = args.ocr_model_path or MODEL_CONFIG["ocr_model_path"]
    train_data_path = args.train_data or DATA_CONFIG["train_data_path"]
    eval_data_path = args.eval_data or DATA_CONFIG["eval_data_path"]
    output_dir = args.output_dir or TRAINING_CONFIG["output_dir"]
    num_epochs = args.num_epochs or TRAINING_CONFIG["num_train_epochs"]
    batch_size = args.batch_size or TRAINING_CONFIG["per_device_train_batch_size"]
    learning_rate = args.learning_rate or TRAINING_CONFIG["learning_rate"]
    gradient_accumulation = args.gradient_accumulation or TRAINING_CONFIG["gradient_accumulation_steps"]
    
    # WandB é…ç½®
    wandb_project = args.wandb_project or TRAINING_CONFIG.get("wandb_project", "OCR-MEM")
    wandb_run_name = args.wandb_run_name or TRAINING_CONFIG["run_name"]
    use_wandb = WANDB_AVAILABLE and not args.disable_wandb
    
    # ==================== éªŒè¯è·¯å¾„ ====================
    print(f"\n{'='*60}")
    print("éªŒè¯é…ç½®å’Œè·¯å¾„")
    print(f"{'='*60}\n")
    
    # æ£€æŸ¥æ¨¡å‹è·¯å¾„
    if not os.path.exists(base_model_path):
        print(f"âš ï¸  è­¦å‘Š: åŸºç¡€æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {base_model_path}")
        print(f"   è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ï¼Œæˆ–è€…è¿™æ˜¯ä¸€ä¸ª HuggingFace æ¨¡å‹ ID")
    else:
        print(f"âœ“ åŸºç¡€æ¨¡å‹è·¯å¾„: {base_model_path}")
    
    if not os.path.exists(ocr_model_path):
        print(f"âš ï¸  è­¦å‘Š: OCR æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {ocr_model_path}")
        print(f"   è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ï¼Œæˆ–è€…è¿™æ˜¯ä¸€ä¸ª HuggingFace æ¨¡å‹ ID")
    else:
        print(f"âœ“ OCR æ¨¡å‹è·¯å¾„: {ocr_model_path}")
    
    # æ£€æŸ¥æ•°æ®è·¯å¾„
    if not os.path.exists(train_data_path):
        raise FileNotFoundError(f"è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {train_data_path}")
    print(f"âœ“ è®­ç»ƒæ•°æ®: {train_data_path}")
    
    if eval_data_path and os.path.exists(eval_data_path):
        print(f"âœ“ éªŒè¯æ•°æ®: {eval_data_path}")
    else:
        print(f"âš ï¸  æœªæ‰¾åˆ°éªŒè¯æ•°æ®ï¼Œå°†è·³è¿‡éªŒè¯: {eval_data_path}")
        eval_data_path = None
    
    print(f"âœ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # ==================== åˆ›å»º DeepSpeed é…ç½® ====================
    print(f"\n{'='*60}")
    print("é…ç½® DeepSpeed")
    print(f"{'='*60}")
    
    deepspeed_config = args.deepspeed or DEEPSPEED_CONFIG_PATH
    
    if deepspeed_config is None:
        # è‡ªåŠ¨ç”Ÿæˆ DeepSpeed é…ç½®
        deepspeed_config = create_deepspeed_config(
            output_dir=output_dir,
            per_device_batch_size=batch_size,
            gradient_accumulation_steps=gradient_accumulation,
            max_grad_norm=TRAINING_CONFIG["max_grad_norm"],
            logging_steps=TRAINING_CONFIG["logging_steps"],
        )
    elif os.path.exists(deepspeed_config):
        print(f"âœ“ ä½¿ç”¨æŒ‡å®šçš„ DeepSpeed é…ç½®: {deepspeed_config}")
    else:
        raise FileNotFoundError(f"DeepSpeed é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {deepspeed_config}")
    
    # ==================== åˆ›å»ºè®­ç»ƒå‚æ•° ====================
    print(f"\n{'='*60}")
    print("åˆ›å»ºè®­ç»ƒå‚æ•°")
    print(f"{'='*60}\n")
    
    training_args = AdapterTrainingArguments(
        # è¾“å‡ºé…ç½®
        output_dir=output_dir,
        run_name=TRAINING_CONFIG["run_name"],
        
        # æ¨¡å‹é…ç½®
        base_model_name=base_model_path,
        ocr_model_name=ocr_model_path,
        vision_embedding_size=MODEL_CONFIG["vision_embedding_size"],
        context_threshold=MODEL_CONFIG["context_threshold"],
        
        # æ•°æ®é…ç½®
        train_data_path=train_data_path,
        eval_data_path=eval_data_path,
        max_seq_length=DATA_CONFIG["max_seq_length"],
        
        # è®­ç»ƒè¶…å‚æ•°
        num_train_epochs=num_epochs,
        per_device_train_batch_size=batch_size,
        per_device_eval_batch_size=TRAINING_CONFIG["per_device_eval_batch_size"],
        gradient_accumulation_steps=gradient_accumulation,
        
        # ä¼˜åŒ–å™¨é…ç½®
        learning_rate=learning_rate,
        warmup_ratio=TRAINING_CONFIG["warmup_ratio"],
        weight_decay=TRAINING_CONFIG["weight_decay"],
        max_grad_norm=TRAINING_CONFIG["max_grad_norm"],
        
        # ç²¾åº¦é…ç½®
        bf16=True,
        tf32=True,
        
        # è¯„ä¼°ä¸ä¿å­˜
        eval_strategy=TRAINING_CONFIG["eval_strategy"] if eval_data_path else "no",
        eval_steps=TRAINING_CONFIG["eval_steps"],
        save_strategy=TRAINING_CONFIG["save_strategy"],
        save_steps=TRAINING_CONFIG["save_steps"],
        save_total_limit=TRAINING_CONFIG["save_total_limit"],
        logging_steps=TRAINING_CONFIG["logging_steps"],
        
        # DeepSpeed
        deepspeed=deepspeed_config,
        
        # å…¶ä»–é…ç½®
        dataloader_num_workers=TRAINING_CONFIG["dataloader_num_workers"],
        remove_unused_columns=False,
        report_to=["wandb", "tensorboard"] if use_wandb else ["tensorboard"],
        seed=TRAINING_CONFIG["seed"],
        
        # é€‚é…å™¨é…ç½®
        save_adapter_only=True,
    )
    
    # ==================== åˆå§‹åŒ– WandB ====================
    if use_wandb:
        # åªåœ¨ä¸»è¿›ç¨‹åˆå§‹åŒ– wandb
        local_rank = int(os.environ.get("LOCAL_RANK", -1))
        if local_rank <= 0:
            print(f"\n{'='*60}")
            print("åˆå§‹åŒ– WandB")
            print(f"{'='*60}\n")
            
            wandb.init(
                project=wandb_project,
                name=wandb_run_name,
                config={
                    "base_model": base_model_path,
                    "ocr_model": ocr_model_path,
                    "num_epochs": num_epochs,
                    "batch_size": batch_size,
                    "gradient_accumulation": gradient_accumulation,
                    "learning_rate": learning_rate,
                    "max_seq_length": DATA_CONFIG["max_seq_length"],
                    "vision_embedding_size": MODEL_CONFIG["vision_embedding_size"],
                    "context_threshold": MODEL_CONFIG["context_threshold"],
                },
                reinit=True,
            )
            print(f"âœ“ WandB é¡¹ç›®: {wandb_project}")
            print(f"âœ“ WandB å®éªŒ: {wandb_run_name}")
    
    print(f"\nâœ“ è®­ç»ƒè½®æ•°: {num_epochs}")
    print(f"âœ“ æ¯ GPU Batch Size: {batch_size}")
    print(f"âœ“ æ¢¯åº¦ç´¯ç§¯: {gradient_accumulation}")
    print(f"âœ“ å­¦ä¹ ç‡: {learning_rate}")
    
    # ==================== åˆå§‹åŒ–æ¨¡å‹ ====================
    print(f"\n{'='*60}")
    print("åˆå§‹åŒ–æ¨¡å‹")
    print(f"{'='*60}\n")
    
    # åˆ›å»ºæ¨¡å‹é…ç½®
    model_config = MEMConfig(
        base_model_name=base_model_path,
        ocr_model_name=ocr_model_path,
        vision_embedding_size=MODEL_CONFIG["vision_embedding_size"],
        context_threshold=MODEL_CONFIG["context_threshold"],
    )
    
    # åˆå§‹åŒ–æ¨¡å‹
    print("æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...")
    model = MEMModel(config=model_config)
    tokenizer = model.tokenizer
    
    # ç¡®ä¿ tokenizer æœ‰ pad_token
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
        tokenizer.pad_token_id = tokenizer.eos_token_id
    
    print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
    model.print_trainable_parameters()
    
    # ==================== åŠ è½½æ•°æ®é›† ====================
    print(f"\n{'='*60}")
    print("åŠ è½½æ•°æ®é›†")
    print(f"{'='*60}\n")
    
    train_dataset = MultiTurnConversationDataset(
        jsonl_path=train_data_path,
        tokenizer=tokenizer,
        max_length=DATA_CONFIG["max_seq_length"],
        return_dict=False,
    )
    print(f"âœ“ è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    
    eval_dataset = None
    if eval_data_path:
        eval_dataset = MultiTurnConversationDataset(
            jsonl_path=eval_data_path,
            tokenizer=tokenizer,
            max_length=DATA_CONFIG["max_seq_length"],
            return_dict=False,
        )
        print(f"âœ“ éªŒè¯é›†: {len(eval_dataset)} æ ·æœ¬")
    
    # ==================== åˆå§‹åŒ–è®­ç»ƒå™¨ ====================
    print(f"\n{'='*60}")
    print("åˆå§‹åŒ–è®­ç»ƒå™¨")
    print(f"{'='*60}\n")
    
    trainer = AdapterOnlyTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        tokenizer=tokenizer,
        data_collator=partial(collate_fn, tokenizer=tokenizer),
    )
    
    print("âœ“ è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
    
    # ==================== å¼€å§‹è®­ç»ƒ ====================
    print(f"\n{'='*60}")
    print("å¼€å§‹è®­ç»ƒ")
    print(f"{'='*60}\n")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯æ¢å¤çš„æ£€æŸ¥ç‚¹
    checkpoint = None
    if os.path.exists(output_dir):
        checkpoints = [
            d for d in os.listdir(output_dir) 
            if d.startswith("checkpoint-")
        ]
        if checkpoints:
            latest = max(checkpoints, key=lambda x: int(x.split("-")[-1]))
            checkpoint = os.path.join(output_dir, latest)
            print(f"âœ“ å‘ç°æ£€æŸ¥ç‚¹ï¼Œå°†ä» {checkpoint} æ¢å¤è®­ç»ƒ\n")
    
    # å¼€å§‹è®­ç»ƒ
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
    
    # ==================== ä¿å­˜æœ€ç»ˆæ¨¡å‹ ====================
    final_dir = os.path.join(output_dir, "final_adapter")
    trainer.save_model(final_dir)
    
    # ä¿å­˜è®­ç»ƒæŒ‡æ ‡
    metrics = train_result.metrics
    trainer.log_metrics("train", metrics)
    trainer.save_metrics("train", metrics)
    
    # å®Œæˆæç¤º
    print(f"\n{'='*60}")
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"{'='*60}")
    print(f"âœ“ æœ€ç»ˆé€‚é…å™¨: {final_dir}")
    print(f"âœ“ è®­ç»ƒæŸå¤±: {metrics.get('train_loss', 'N/A'):.4f}")
    print(f"âœ“ æ€»æ­¥æ•°: {metrics.get('train_steps', 'N/A')}")
    print(f"{'='*60}\n")
    
    # å…³é—­ WandB
    if use_wandb:
        local_rank = int(os.environ.get("LOCAL_RANK", -1))
        if local_rank <= 0:
            wandb.finish()
            print("âœ“ WandB æ—¥å¿—å·²åŒæ­¥å®Œæˆ")


# ============================================================================
# ç¨‹åºå…¥å£
# ============================================================================

if __name__ == "__main__":
    main()
