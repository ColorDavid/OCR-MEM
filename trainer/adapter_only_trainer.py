"""
================================================================================
Adapter-Only SFT Trainer for MEMModel
================================================================================

æœ¬æ¨¡å—å®ç°äº†ä¸€ä¸ªä¸“é—¨ç”¨äºè®­ç»ƒ MEMModel æŠ•å½±é€‚é…å™¨ (Projection Adapter) çš„è®­ç»ƒå™¨ã€‚

æ ¸å¿ƒè®¾è®¡ç†å¿µï¼š
1. åªè®­ç»ƒæŠ•å½±å±‚ (proj)ï¼Œå†»ç»“åŸºç¡€è¯­è¨€æ¨¡å‹å’Œ OCR ç¼–ç å™¨
2. ä½¿ç”¨ DeepSpeed ZeRO-2 ä¼˜åŒ–ï¼Œæ”¯æŒ CPU offloading ä»¥èŠ‚çœ GPU æ˜¾å­˜
3. åªä¿å­˜é€‚é…å™¨æƒé‡ï¼Œè€Œéæ•´ä¸ªæ¨¡å‹ï¼Œæå¤§å‡å°‘å­˜å‚¨éœ€æ±‚

é€‚ç”¨åœºæ™¯ï¼š
- åœ¨é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹åŸºç¡€ä¸Šå¾®è°ƒæŠ•å½±å±‚
- èµ„æºå—é™ç¯å¢ƒä¸‹çš„é«˜æ•ˆè®­ç»ƒ
- å¿«é€Ÿè¿­ä»£å®éªŒ

ä¾èµ–ï¼š
- transformers: HuggingFace Trainer å’Œ TrainingArguments
- deepspeed: åˆ†å¸ƒå¼è®­ç»ƒå’Œå†…å­˜ä¼˜åŒ– (å¯é€‰)
- torch: PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶

ä½œè€…ï¼šOCR-MEM Team
æ›´æ–°æ—¥æœŸï¼š2024
================================================================================
"""

import os
import json
import torch
import torch.distributed as dist
from typing import Optional, Dict, Any, Union, List
from dataclasses import dataclass, field
from functools import partial

try:
    import wandb
    WANDB_AVAILABLE = True
except ImportError:
    WANDB_AVAILABLE = False

from transformers import (
    Trainer,
    TrainingArguments,
)
from transformers.modeling_utils import unwrap_model

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å‹å’Œæ•°æ®å¤„ç†æ¨¡å—
from mem_adapter_only import MEMModel, MEMConfig
from utils.data import MultiTurnConversationDataset, collate_fn


# ============================================================================
# è®­ç»ƒå‚æ•°é…ç½®ç±»
# ============================================================================

@dataclass
class AdapterTrainingArguments(TrainingArguments):
    """
    æ‰©å±•çš„è®­ç»ƒå‚æ•°ç±»ï¼Œç»§æ‰¿è‡ª HuggingFace TrainingArguments
    
    æ–°å¢å‚æ•°åˆ†ä¸ºä¸‰ç±»ï¼š
    1. æ¨¡å‹é…ç½® (Model Config): å®šä¹‰æ¨¡å‹ç»“æ„ç›¸å…³å‚æ•°
    2. æ•°æ®é…ç½® (Data Config): å®šä¹‰æ•°æ®é›†è·¯å¾„å’Œå¤„ç†å‚æ•°
    3. é€‚é…å™¨é…ç½® (Adapter Config): æ§åˆ¶é€‚é…å™¨ä¿å­˜è¡Œä¸º
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        args = AdapterTrainingArguments(
            output_dir="./checkpoints",
            base_model_name="Qwen/Qwen2.5-1.5B-Instruct",
            per_device_train_batch_size=2,
            learning_rate=2e-4,
        )
    """
    
    # -------------------- æ¨¡å‹é…ç½® --------------------
    base_model_name: str = field(
        default="Qwen/Qwen2.5-1.5B-Instruct",
        metadata={"help": "åŸºç¡€è¯­è¨€æ¨¡å‹çš„ HuggingFace æ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„"}
    )
    ocr_model_name: str = field(
        default="deepseek-ai/DeepSeek-OCR",
        metadata={"help": "OCR è§†è§‰ç¼–ç å™¨çš„æ¨¡å‹åç§°æˆ–è·¯å¾„"}
    )
    vision_embedding_size: int = field(
        default=512,
        metadata={"help": "è§†è§‰ç¼–ç å™¨è¾“å‡ºçš„åµŒå…¥ç»´åº¦"}
    )
    context_threshold: int = field(
        default=2048,
        metadata={"help": "è§¦å‘è§†è§‰å‹ç¼©çš„ä¸Šä¸‹æ–‡é•¿åº¦é˜ˆå€¼ï¼ˆè¶…è¿‡æ­¤é•¿åº¦å°†å‹ç¼©å†å²ä¸ºè§†è§‰åµŒå…¥ï¼‰"}
    )
    
    # -------------------- æ•°æ®é…ç½® --------------------
    train_data_path: str = field(
        default="data/train.jsonl",
        metadata={"help": "è®­ç»ƒæ•°æ® JSONL æ–‡ä»¶è·¯å¾„"}
    )
    eval_data_path: Optional[str] = field(
        default=None,
        metadata={"help": "éªŒè¯æ•°æ® JSONL æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰"}
    )
    max_seq_length: int = field(
        default=2048,
        metadata={"help": "æœ€å¤§åºåˆ—é•¿åº¦ï¼Œè¶…è¿‡æ­¤é•¿åº¦å°†è¢«æˆªæ–­"}
    )
    
    # -------------------- é€‚é…å™¨é…ç½® --------------------
    save_adapter_only: bool = field(
        default=True,
        metadata={"help": "æ˜¯å¦åªä¿å­˜é€‚é…å™¨æƒé‡ï¼ˆTrueï¼‰æˆ–å®Œæ•´æ¨¡å‹ï¼ˆFalseï¼‰"}
    )


# ============================================================================
# é€‚é…å™¨è®­ç»ƒå™¨ç±»
# ============================================================================

class AdapterOnlyTrainer(Trainer):
    """
    ä¸“é—¨ç”¨äºè®­ç»ƒ MEMModel æŠ•å½±é€‚é…å™¨çš„è®­ç»ƒå™¨
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. è‡ªåŠ¨å†»ç»“éé€‚é…å™¨å‚æ•°ï¼Œåªè®­ç»ƒ proj å±‚
    2. è‡ªå®šä¹‰ä¿å­˜é€»è¾‘ï¼Œåªä¿å­˜é€‚é…å™¨æƒé‡
    3. ä¸ MEMModel çš„ save_pretrained/from_pretrained å…¼å®¹
    4. æ”¯æŒ DeepSpeed ZeRO ä¼˜åŒ–
    
    ç»§æ‰¿è‡ª HuggingFace Trainerï¼Œä¿ç•™æ‰€æœ‰åŸæœ‰åŠŸèƒ½ï¼š
    - åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
    - æ··åˆç²¾åº¦è®­ç»ƒ (bf16/fp16)
    - æ¢¯åº¦ç´¯ç§¯
    - å­¦ä¹ ç‡è°ƒåº¦
    - æ—¥å¿—è®°å½•å’Œæ£€æŸ¥ç‚¹ä¿å­˜
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        trainer = AdapterOnlyTrainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            tokenizer=tokenizer,
        )
        trainer.train()
    """
    
    def __init__(
        self, 
        model: MEMModel, 
        args: AdapterTrainingArguments, 
        **kwargs
    ):
        """
        åˆå§‹åŒ–é€‚é…å™¨è®­ç»ƒå™¨
        
        Args:
            model (MEMModel): MEMModel å®ä¾‹ï¼Œå°†è‡ªåŠ¨å†»ç»“éé€‚é…å™¨å‚æ•°
            args (AdapterTrainingArguments): è®­ç»ƒå‚æ•°é…ç½®
            **kwargs: ä¼ é€’ç»™çˆ¶ç±» Trainer çš„å…¶ä»–å‚æ•°ï¼Œå¦‚ï¼š
                - train_dataset: è®­ç»ƒæ•°æ®é›†
                - eval_dataset: éªŒè¯æ•°æ®é›†
                - tokenizer: åˆ†è¯å™¨
                - data_collator: æ•°æ®æ•´ç†å‡½æ•°
                - callbacks: å›è°ƒå‡½æ•°åˆ—è¡¨
        
        æ³¨æ„ï¼š
            æ¨¡å‹å‚æ•°å†»ç»“åœ¨è°ƒç”¨çˆ¶ç±» __init__ ä¹‹å‰å®Œæˆï¼Œ
            ç¡®ä¿ä¼˜åŒ–å™¨åªåŒ…å«å¯è®­ç»ƒå‚æ•°
        """
        # åœ¨è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ä¹‹å‰ï¼Œè®¾ç½®å¯è®­ç»ƒå‚æ•°
        # è¿™å¾ˆé‡è¦ï¼Œå› ä¸º Trainer ä¼šæ ¹æ® requires_grad åˆ›å»ºä¼˜åŒ–å™¨
        self._setup_trainable_params(model, args)
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(model=model, args=args, **kwargs)
    
    def _setup_trainable_params(
        self, 
        model: MEMModel, 
        args: AdapterTrainingArguments
    ) -> None:
        """
        è®¾ç½®æ¨¡å‹çš„å¯è®­ç»ƒå‚æ•°
        
        ç­–ç•¥ï¼š
        1. é¦–å…ˆå†»ç»“æ‰€æœ‰å‚æ•°
        2. ç„¶ååªè§£å†» proj (æŠ•å½±å±‚) çš„å‚æ•°
        3. éªŒè¯åªæœ‰é¢„æœŸçš„å‚æ•°æ˜¯å¯è®­ç»ƒçš„
        
        Args:
            model: MEMModel å®ä¾‹
            args: è®­ç»ƒå‚æ•°ï¼ˆå½“å‰æœªä½¿ç”¨ï¼Œé¢„ç•™æ‰©å±•ï¼‰
        
        Raises:
            ValueError: å¦‚æœå‘ç°é proj å±‚çš„å‚æ•°æ˜¯å¯è®­ç»ƒçš„
        
        æ•ˆæœï¼š
            - åŸºç¡€è¯­è¨€æ¨¡å‹å‚æ•°: å†»ç»“
            - OCR ç¼–ç å™¨å‚æ•°: å†»ç»“
            - æŠ•å½±å±‚å‚æ•°: å¯è®­ç»ƒ
        """
        # Step 1: å†»ç»“æ‰€æœ‰å‚æ•°
        for param in model.parameters():
            param.requires_grad = False
        
        # Step 2: è§£å†»æŠ•å½±é€‚é…å™¨
        for param in model.proj.parameters():
            param.requires_grad = True
        
        # Step 3: ç»Ÿè®¡å¹¶æ‰“å°å‚æ•°ä¿¡æ¯
        trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
        total = sum(p.numel() for p in model.parameters())
        
        print(f"\n{'='*60}")
        print(f"å‚æ•°ç»Ÿè®¡ (Parameter Statistics)")
        print(f"{'='*60}")
        print(f"å¯è®­ç»ƒå‚æ•° (Trainable):     {trainable:,}")
        print(f"æ€»å‚æ•° (Total):             {total:,}")
        print(f"å¯è®­ç»ƒæ¯”ä¾‹ (Trainable %):   {100*trainable/total:.4f}%")
        print(f"{'='*60}\n")
        
        # Step 4: å®‰å…¨æ£€æŸ¥ - ç¡®ä¿åªæœ‰ proj å±‚æ˜¯å¯è®­ç»ƒçš„
        for name, param in model.named_parameters():
            if param.requires_grad and 'proj' not in name:
                raise ValueError(
                    f"å®‰å…¨æ£€æŸ¥å¤±è´¥: å‚æ•° '{name}' æ˜¯å¯è®­ç»ƒçš„ï¼Œä½†å®ƒä¸å±äº proj å±‚ï¼\n"
                    f"è¿™å¯èƒ½å¯¼è‡´æ„å¤–çš„å‚æ•°æ›´æ–°ã€‚è¯·æ£€æŸ¥æ¨¡å‹ç»“æ„ã€‚"
                )
    
    def log(self, logs: Dict[str, float]) -> None:
        """
        é‡å†™æ—¥å¿—æ–¹æ³•ï¼Œæ·»åŠ é¢å¤–çš„è®­ç»ƒç›‘æ§æŒ‡æ ‡
        
        Args:
            logs: æ—¥å¿—å­—å…¸
        """
        # æ·»åŠ é¢å¤–çš„ç›‘æ§æŒ‡æ ‡
        if self.state.global_step > 0:
            # æ·»åŠ å­¦ä¹ ç‡ä¿¡æ¯
            if "learning_rate" not in logs and self.lr_scheduler is not None:
                logs["learning_rate"] = self.lr_scheduler.get_last_lr()[0]
            
            # æ·»åŠ è®­ç»ƒè¿›åº¦
            if hasattr(self.state, "max_steps") and self.state.max_steps > 0:
                logs["progress"] = self.state.global_step / self.state.max_steps
        
        # è°ƒç”¨çˆ¶ç±»çš„ log æ–¹æ³•ï¼ˆä¼šè‡ªåŠ¨å‘é€åˆ° wandbï¼‰
        super().log(logs)
    
    def compute_loss(
        self, 
        model: MEMModel, 
        inputs: Dict[str, torch.Tensor], 
        return_outputs: bool = False,
        num_items_in_batch: Optional[int] = None,
    ) -> Union[torch.Tensor, tuple]:
        """
        è®¡ç®—è®­ç»ƒæŸå¤±
        
        é‡å†™æ­¤æ–¹æ³•ä»¥ç¡®ä¿ä¸ MEMModel çš„ forward æ–¹æ³•æ­£ç¡®é…åˆã€‚
        MEMModel.forward è¿”å›åŒ…å« loss çš„ CausalLMOutputWithPast å¯¹è±¡ã€‚
        
        Args:
            model: æ¨¡å‹å®ä¾‹ï¼ˆå¯èƒ½è¢« DeepSpeed/FSDP åŒ…è£…ï¼‰
            inputs: è¾“å…¥å­—å…¸ï¼ŒåŒ…å«ï¼š
                - input_ids: è¾“å…¥ token IDs [batch_size, seq_len]
                - attention_mask: æ³¨æ„åŠ›æ©ç  [batch_size, seq_len]
                - labels: æ ‡ç­¾ï¼Œ-100 è¡¨ç¤ºä¸è®¡ç®—æŸå¤± [batch_size, seq_len]
            return_outputs: æ˜¯å¦è¿”å›æ¨¡å‹è¾“å‡º
            num_items_in_batch: æ‰¹æ¬¡ä¸­çš„æ ·æœ¬æ•°ï¼ˆç”¨äºæ¢¯åº¦ç´¯ç§¯å½’ä¸€åŒ–ï¼‰
        
        Returns:
            å¦‚æœ return_outputs=False: è¿”å› loss (torch.Tensor)
            å¦‚æœ return_outputs=True: è¿”å› (loss, outputs) å…ƒç»„
        """
        # ç§»é™¤éæ¨¡å‹å‚æ•°ï¼ˆå¦‚ messages ç­‰è°ƒè¯•ä¿¡æ¯ï¼‰
        # è¿™äº›å¯èƒ½ç”± data_collator æ·»åŠ ï¼Œä½†ä¸åº”ä¼ å…¥æ¨¡å‹
        model_inputs = {
            k: v for k, v in inputs.items() 
            if k in ['input_ids', 'attention_mask', 'labels', 'position_ids']
        }
        
        # å‰å‘ä¼ æ’­
        outputs = model(**model_inputs)
        
        # è·å–æŸå¤±
        # MEMModel.forward åœ¨æœ‰ labels æ—¶ä¼šè‡ªåŠ¨è®¡ç®—æŸå¤±
        loss = outputs.loss
        
        # å¯é€‰ï¼šæ·»åŠ é¢å¤–çš„æŸå¤±ç›‘æ§æ—¥å¿—
        if self.args.logging_steps > 0 and self.state.global_step % self.args.logging_steps == 0:
            if hasattr(self, '_log_loss_once'):
                pass  # é¿å…é‡å¤æ—¥å¿—
            else:
                self._log_loss_once = True
        
        return (loss, outputs) if return_outputs else loss
    
    def _save(
        self, 
        output_dir: Optional[str] = None, 
        state_dict: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹
        
        æ ¹æ® save_adapter_only é…ç½®ï¼š
        - True: åªä¿å­˜é€‚é…å™¨æƒé‡ï¼ˆæ¨èï¼ŒèŠ‚çœå­˜å‚¨ç©ºé—´ï¼‰
        - False: ä¿å­˜å®Œæ•´æ¨¡å‹
        
        ä¿å­˜çš„æ–‡ä»¶æ ¼å¼ä¸ MEMModel.from_pretrained å…¼å®¹ï¼š
        - config.json: æ¨¡å‹é…ç½®
        - projection_layer.pt: æŠ•å½±å±‚æƒé‡
        
        Args:
            output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨ args.output_dir
            state_dict: å¯é€‰çš„ state_dictï¼Œé€šå¸¸ç”± DeepSpeed æä¾›
        
        æ³¨æ„ï¼š
            åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œåªæœ‰ä¸»è¿›ç¨‹ (rank 0) ä¼šæ‰§è¡Œä¿å­˜æ“ä½œ
        """
        output_dir = output_dir or self.args.output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # è·å–å®é™…çš„æ¨¡å‹ï¼ˆå¯èƒ½è¢« DataParallel/DeepSpeed åŒ…è£…ï¼‰
        model = unwrap_model(self.model)
        
        if self.args.save_adapter_only:
            # ============ åªä¿å­˜é€‚é…å™¨æƒé‡ ============
            
            # æå– proj å±‚çš„æƒé‡
            if state_dict is not None:
                # ä»æä¾›çš„ state_dict ä¸­æå–ï¼ˆDeepSpeed ZeRO-3 åœºæ™¯ï¼‰
                proj_state_dict = {
                    k.replace("proj.", ""): v.cpu()
                    for k, v in state_dict.items()
                    if k.startswith("proj.")
                }
            else:
                # ç›´æ¥ä»æ¨¡å‹è·å–
                proj_state_dict = {
                    k: v.cpu() for k, v in model.proj.state_dict().items()
                }
            
            # ä¿å­˜æŠ•å½±å±‚æƒé‡ï¼ˆä¸ MEMModel.save_pretrained æ ¼å¼ä¸€è‡´ï¼‰
            torch.save(
                proj_state_dict, 
                os.path.join(output_dir, "projection_layer.pt")
            )
            
            # ä¿å­˜é…ç½®ï¼ˆä¸ MEMModel.save_pretrained æ ¼å¼ä¸€è‡´ï¼‰
            config_dict = {
                "model_type": model.config.model_type,
                "base_model_name": model.config.base_model_name,
                "ocr_model_name": model.config.ocr_model_name,
                "vision_embedding_size": model.config.vision_embedding_size,
                "context_threshold": model.config.context_threshold,
            }
            with open(os.path.join(output_dir, "config.json"), "w") as f:
                json.dump(config_dict, f, indent=2)
            
            print(f"âœ“ å·²ä¿å­˜é€‚é…å™¨åˆ° {output_dir}")
            print(f"  - projection_layer.pt: æŠ•å½±å±‚æƒé‡")
            print(f"  - config.json: æ¨¡å‹é…ç½®")
            
        else:
            # ============ ä¿å­˜å®Œæ•´æ¨¡å‹ ============
            # ä½¿ç”¨ MEMModel çš„ save_pretrained æ–¹æ³•
            model.save_pretrained(
                output_dir,
                is_main_process=self.args.should_save,
                state_dict=state_dict,
            )
            print(f"âœ“ å·²ä¿å­˜å®Œæ•´æ¨¡å‹åˆ° {output_dir}")
        
        # ä¿å­˜ tokenizerï¼ˆç”¨äºæ¨ç†æ—¶åŠ è½½ï¼‰
        if self.tokenizer is not None:
            self.tokenizer.save_pretrained(output_dir)
            print(f"  - tokenizer: åˆ†è¯å™¨é…ç½®")
    
    def _load_from_checkpoint(
        self, 
        resume_from_checkpoint: str,
        model: Optional[MEMModel] = None
    ) -> None:
        """
        ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
        
        æ”¯æŒä¸¤ç§æ£€æŸ¥ç‚¹æ ¼å¼ï¼š
        1. é€‚é…å™¨æ ¼å¼: åªæœ‰ projection_layer.pt
        2. å®Œæ•´æ¨¡å‹æ ¼å¼: ä½¿ç”¨ MEMModel.from_pretrained
        
        Args:
            resume_from_checkpoint: æ£€æŸ¥ç‚¹ç›®å½•è·¯å¾„
            model: å¯é€‰çš„æ¨¡å‹å®ä¾‹
        """
        if model is None:
            model = unwrap_model(self.model)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºé€‚é…å™¨æ ¼å¼
        proj_path = os.path.join(resume_from_checkpoint, "projection_layer.pt")
        
        if os.path.exists(proj_path):
            # åŠ è½½é€‚é…å™¨æƒé‡
            proj_state_dict = torch.load(proj_path, map_location="cpu", weights_only=True)
            model.proj.load_state_dict(proj_state_dict)
            print(f"âœ“ ä» {proj_path} åŠ è½½äº†é€‚é…å™¨æƒé‡")
        else:
            # å°è¯•åŠ è½½å®Œæ•´æ£€æŸ¥ç‚¹
            super()._load_from_checkpoint(resume_from_checkpoint, model)



# ============================================================================
# DeepSpeed é…ç½®è¾…åŠ©å‡½æ•°
# ============================================================================

def get_world_size() -> int:
    """
    è·å–åˆ†å¸ƒå¼è®­ç»ƒçš„ world sizeï¼ˆè¿›ç¨‹æ€»æ•°ï¼‰
    
    Returns:
        int: è¿›ç¨‹æ•°ï¼Œéåˆ†å¸ƒå¼ç¯å¢ƒè¿”å› 1
    
    è¯´æ˜ï¼š
        - åˆ†å¸ƒå¼ç¯å¢ƒï¼šè¿”å›æ‰€æœ‰å‚ä¸è®­ç»ƒçš„ GPU/è¿›ç¨‹æ•°
        - å•æœºç¯å¢ƒï¼šè¿”å› 1
    """
    if dist.is_available() and dist.is_initialized():
        return dist.get_world_size()
    return 1


def setup_deepspeed_config(args: AdapterTrainingArguments) -> str:
    """
    åˆ›å»º DeepSpeed ZeRO-2 é…ç½®æ–‡ä»¶
    
    DeepSpeed ä¼˜åŒ–ç­–ç•¥ï¼š
    - ZeRO Stage 2: ä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡ + æ¢¯åº¦åˆ†ç‰‡
    - CPU Offloading: å°†ä¼˜åŒ–å™¨çŠ¶æ€ç§»è‡³ CPUï¼ŒèŠ‚çœ GPU æ˜¾å­˜
    - BF16 æ··åˆç²¾åº¦: ä½¿ç”¨ bfloat16 ä»¥æé«˜è®­ç»ƒæ•ˆç‡
    
    é…ç½®å‚æ•°è¯´æ˜ï¼š
    - train_batch_size: å…¨å±€ batch size = per_gpu * accumulation * world_size
    - train_micro_batch_size_per_gpu: æ¯ä¸ª GPU æ¯æ¬¡å‰å‘çš„ batch size
    - offload_optimizer: å°† Adam ä¼˜åŒ–å™¨çŠ¶æ€ç§»åˆ° CPU
    
    Args:
        args: è®­ç»ƒå‚æ•°é…ç½®
    
    Returns:
        str: DeepSpeed é…ç½®æ–‡ä»¶çš„è·¯å¾„
    
    æ³¨æ„ï¼š
        è¯¥é…ç½®ä¸“ä¸ºé€‚é…å™¨è®­ç»ƒä¼˜åŒ–ï¼Œé€‚åˆæ˜¾å­˜å—é™çš„ç¯å¢ƒ
    """
    # è·å–åˆ†å¸ƒå¼è®­ç»ƒçš„ world size
    world_size = get_world_size()
    
    # è®¡ç®—æ‰¹æ¬¡å¤§å°
    # æœ‰æ•ˆ batch size = per_device_batch * gradient_accumulation * world_size
    train_batch_size = (
        args.per_device_train_batch_size * 
        args.gradient_accumulation_steps * 
        world_size
    )
    micro_batch_size = args.per_device_train_batch_size
    
    # ============ DeepSpeed é…ç½® ============
    config = {
        # -------- æ‰¹æ¬¡é…ç½®ï¼ˆå¿…é¡»æ­£ç¡®è®¾ç½®ï¼‰ --------
        "train_batch_size": train_batch_size,
        "train_micro_batch_size_per_gpu": micro_batch_size,
        "gradient_accumulation_steps": args.gradient_accumulation_steps,
        
        # -------- ç²¾åº¦é…ç½® --------
        # ä½¿ç”¨ bfloat16 æ··åˆç²¾åº¦è®­ç»ƒ
        # bf16 ç›¸æ¯” fp16 æœ‰æ›´å¤§çš„åŠ¨æ€èŒƒå›´ï¼Œæ›´ç¨³å®š
        "bf16": {
            "enabled": True
        },
        "fp16": {
            "enabled": False
        },
        
        # -------- ZeRO Stage 2 ä¼˜åŒ– --------
        # ZeRO-2: åˆ†ç‰‡ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦
        # æ˜¾å­˜èŠ‚çœçº¦ 50-60%ï¼Œé€‚åˆå¤§æ¨¡å‹å¾®è°ƒ
        "zero_optimization": {
            "stage": 2,  # Stage 2: ä¼˜åŒ–å™¨çŠ¶æ€ + æ¢¯åº¦åˆ†ç‰‡
            
            # å°†ä¼˜åŒ–å™¨çŠ¶æ€ç§»åˆ° CPUï¼ˆä¸»è¦æ˜¾å­˜èŠ‚çœæ¥æºï¼‰
            # Adam æœ‰ä¸¤ä¸ª momentum bufferï¼Œå ç”¨å¤§é‡æ˜¾å­˜
            "offload_optimizer": {
                "device": "cpu",
                "pin_memory": True  # ä½¿ç”¨ pinned memory åŠ é€Ÿ CPU-GPU ä¼ è¾“
            },
            
            # é€šä¿¡ä¼˜åŒ–å‚æ•°
            "allgather_partitions": True,       # ä½¿ç”¨ allgather æ”¶é›†æ¢¯åº¦
            "allgather_bucket_size": 5e8,       # allgather bucket å¤§å°
            "reduce_scatter": True,              # ä½¿ç”¨ reduce_scatter
            "reduce_bucket_size": 5e8,          # reduce bucket å¤§å°
            "overlap_comm": True,               # é€šä¿¡å’Œè®¡ç®—é‡å 
            "contiguous_gradients": True,       # ä½¿ç”¨è¿ç»­å†…å­˜å­˜å‚¨æ¢¯åº¦
        },
        
        # -------- æ¢¯åº¦è£å‰ª --------
        "gradient_clipping": args.max_grad_norm,
        
        # -------- æ—¥å¿—é…ç½® --------
        "steps_per_print": args.logging_steps,
        "wall_clock_breakdown": False,  # å…³é—­æ€§èƒ½åˆ†æä»¥æé«˜é€Ÿåº¦
    }
    
    # ä¿å­˜é…ç½®æ–‡ä»¶
    config_path = os.path.join(args.output_dir, "ds_config.json")
    os.makedirs(args.output_dir, exist_ok=True)
    
    with open(config_path, "w") as f:
        json.dump(config, f, indent=2)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print(f"\n{'='*60}")
    print("DeepSpeed é…ç½®")
    print(f"{'='*60}")
    print(f"âœ“ é…ç½®æ–‡ä»¶: {config_path}")
    print(f"âœ“ ZeRO Stage: 2 (ä¼˜åŒ–å™¨çŠ¶æ€ + æ¢¯åº¦åˆ†ç‰‡)")
    print(f"âœ“ CPU Offloading: ä¼˜åŒ–å™¨çŠ¶æ€")
    print(f"âœ“ ç²¾åº¦: BFloat16")
    print(f"âœ“ å…¨å±€ Batch Size: {train_batch_size}")
    print(f"âœ“ æ¯ GPU Micro Batch: {micro_batch_size}")
    print(f"âœ“ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {args.gradient_accumulation_steps}")
    print(f"âœ“ World Size: {world_size}")
    print(f"{'='*60}\n")
    
    return config_path


# ============================================================================
# ä¸»è®­ç»ƒå‡½æ•°
# ============================================================================

def train():
    """
    ä¸»è®­ç»ƒå…¥å£å‡½æ•°
    
    æ‰§è¡Œæµç¨‹ï¼š
    1. é…ç½®è®­ç»ƒå‚æ•°
    2. åˆ›å»º DeepSpeed é…ç½®
    3. åŠ è½½æ¨¡å‹
    4. åŠ è½½æ•°æ®é›†
    5. åˆå§‹åŒ–è®­ç»ƒå™¨
    6. æ‰§è¡Œè®­ç»ƒ
    7. ä¿å­˜æœ€ç»ˆé€‚é…å™¨
    
    è¿è¡Œæ–¹å¼ï¼š
        å•æœºå•å¡ï¼š
            python adapter_only_trainer.py
        
        å•æœºå¤šå¡ï¼ˆDeepSpeedï¼‰ï¼š
            deepspeed --num_gpus=4 adapter_only_trainer.py
        
        å¤šæœºå¤šå¡ï¼š
            deepspeed --hostfile=hostfile adapter_only_trainer.py
    """
    
    # ==================== Step 1: é…ç½®è®­ç»ƒå‚æ•° ====================
    print(f"\n{'='*60}")
    print("æ­¥éª¤ 1/6: é…ç½®è®­ç»ƒå‚æ•°")
    print(f"{'='*60}\n")
    
    args = AdapterTrainingArguments(
        # ---------- è¾“å‡ºé…ç½® ----------
        output_dir="./output/adapter_checkpoints",  # æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
        run_name="mem_adapter",                      # å®éªŒåç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        
        # ---------- æ¨¡å‹é…ç½® ----------
        base_model_name="Qwen/Qwen2.5-1.5B-Instruct",  # åŸºç¡€è¯­è¨€æ¨¡å‹
        ocr_model_name="deepseek-ai/DeepSeek-OCR",     # OCR è§†è§‰ç¼–ç å™¨
        vision_embedding_size=512,                      # è§†è§‰åµŒå…¥ç»´åº¦
        context_threshold=2048,                         # è§†è§‰å‹ç¼©é˜ˆå€¼
        
        # ---------- æ•°æ®é…ç½® ----------
        train_data_path="data/train.jsonl",    # è®­ç»ƒæ•°æ®è·¯å¾„
        eval_data_path="data/eval.jsonl",      # éªŒè¯æ•°æ®è·¯å¾„
        max_seq_length=2048,                   # æœ€å¤§åºåˆ—é•¿åº¦
        
        # ---------- è®­ç»ƒè¶…å‚æ•° ----------
        num_train_epochs=3,                    # è®­ç»ƒè½®æ•°
        per_device_train_batch_size=2,         # æ¯ GPU è®­ç»ƒ batch size
        per_device_eval_batch_size=4,          # æ¯ GPU éªŒè¯ batch size
        gradient_accumulation_steps=8,         # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
        
        # ---------- ä¼˜åŒ–å™¨é…ç½® ----------
        learning_rate=2e-4,                    # å­¦ä¹ ç‡
        warmup_ratio=0.1,                      # warmup æ¯”ä¾‹ï¼ˆå‰ 10% æ­¥æ•°ï¼‰
        weight_decay=0.01,                     # æƒé‡è¡°å‡
        max_grad_norm=1.0,                     # æ¢¯åº¦è£å‰ªé˜ˆå€¼
        
        # ---------- ç²¾åº¦é…ç½® ----------
        bf16=True,                             # ä½¿ç”¨ bfloat16
        tf32=True,                             # å¯ç”¨ TF32ï¼ˆA100+ GPUï¼‰
        
        # ---------- è¯„ä¼°ä¸ä¿å­˜ ----------
        eval_strategy="steps",                 # æŒ‰æ­¥æ•°è¯„ä¼°
        eval_steps=200,                        # æ¯ 200 æ­¥è¯„ä¼°
        save_strategy="steps",                 # æŒ‰æ­¥æ•°ä¿å­˜
        save_steps=200,                        # æ¯ 200 æ­¥ä¿å­˜
        save_total_limit=3,                    # æœ€å¤šä¿ç•™ 3 ä¸ªæ£€æŸ¥ç‚¹
        logging_steps=10,                      # æ¯ 10 æ­¥è®°å½•æ—¥å¿—
        
        # ---------- DeepSpeed ----------
        deepspeed=None,  # å°†åœ¨ä¸‹é¢è®¾ç½®
        
        # ---------- å…¶ä»–é…ç½® ----------
        dataloader_num_workers=4,              # æ•°æ®åŠ è½½è¿›ç¨‹æ•°
        remove_unused_columns=False,           # ä¿ç•™æ‰€æœ‰åˆ—ï¼ˆè‡ªå®šä¹‰æ•°æ®æ ¼å¼éœ€è¦ï¼‰
        report_to=["tensorboard"],             # æ—¥å¿—æŠ¥å‘Šç›®æ ‡
        seed=42,                               # éšæœºç§å­
        
        # ---------- é€‚é…å™¨é…ç½® ----------
        save_adapter_only=True,                # åªä¿å­˜é€‚é…å™¨æƒé‡
    )
    
    print("âœ“ è®­ç»ƒå‚æ•°é…ç½®å®Œæˆ")
    
    # ==================== Step 2: é…ç½® DeepSpeed ====================
    print(f"\n{'='*60}")
    print("æ­¥éª¤ 2/6: é…ç½® DeepSpeed")
    print(f"{'='*60}")
    
    # åˆ›å»º DeepSpeed é…ç½®ï¼ˆåœ¨åˆå§‹åŒ– Trainer ä¹‹å‰ï¼‰
    args.deepspeed = setup_deepspeed_config(args)
    
    # ==================== Step 3: åŠ è½½æ¨¡å‹ ====================
    print(f"{'='*60}")
    print("æ­¥éª¤ 3/6: åŠ è½½æ¨¡å‹")
    print(f"{'='*60}\n")
    
    # åˆ›å»ºæ¨¡å‹é…ç½®
    model_config = MEMConfig(
        base_model_name=args.base_model_name,
        ocr_model_name=args.ocr_model_name,
        vision_embedding_size=args.vision_embedding_size,
        context_threshold=args.context_threshold,
    )
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = MEMModel(config=model_config)
    tokenizer = model.tokenizer
    
    # ç¡®ä¿ tokenizer æœ‰ pad_token
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
        tokenizer.pad_token_id = tokenizer.eos_token_id
    
    print(f"âœ“ åŸºç¡€æ¨¡å‹: {args.base_model_name}")
    print(f"âœ“ OCR æ¨¡å‹: {args.ocr_model_name}")
    print(f"âœ“ è§†è§‰åµŒå…¥ç»´åº¦: {args.vision_embedding_size}")
    print(f"âœ“ ä¸Šä¸‹æ–‡é˜ˆå€¼: {args.context_threshold}")
    
    # æ‰“å°å¯è®­ç»ƒå‚æ•°ï¼ˆæ¨¡å‹å†…ç½®æ–¹æ³•ï¼‰
    model.print_trainable_parameters()
    
    # ==================== Step 4: åŠ è½½æ•°æ®é›† ====================
    print(f"\n{'='*60}")
    print("æ­¥éª¤ 4/6: åŠ è½½æ•°æ®é›†")
    print(f"{'='*60}\n")
    
    # åŠ è½½è®­ç»ƒæ•°æ®
    train_dataset = MultiTurnConversationDataset(
        jsonl_path=args.train_data_path,
        tokenizer=tokenizer,
        max_length=args.max_seq_length,
        return_dict=False  # ä¸è¿”å› messages å­—å…¸ï¼Œåªè¿”å›å¼ é‡
    )
    print(f"âœ“ è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    
    # åŠ è½½éªŒè¯æ•°æ®ï¼ˆå¯é€‰ï¼‰
    eval_dataset = None
    if args.eval_data_path and os.path.exists(args.eval_data_path):
        eval_dataset = MultiTurnConversationDataset(
            jsonl_path=args.eval_data_path,
            tokenizer=tokenizer,
            max_length=args.max_seq_length,
            return_dict=False
        )
        print(f"âœ“ éªŒè¯é›†: {len(eval_dataset)} æ ·æœ¬")
    else:
        print(f"âš  æœªæ‰¾åˆ°éªŒè¯æ•°æ®: {args.eval_data_path}")
    
    # ==================== Step 5: åˆå§‹åŒ–è®­ç»ƒå™¨ ====================
    print(f"\n{'='*60}")
    print("æ­¥éª¤ 5/6: åˆå§‹åŒ–è®­ç»ƒå™¨")
    print(f"{'='*60}\n")
    
    trainer = AdapterOnlyTrainer(
        model=model,
        args=args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        tokenizer=tokenizer,
        data_collator=partial(collate_fn, tokenizer=tokenizer),
    )
    
    print("âœ“ AdapterOnlyTrainer åˆå§‹åŒ–å®Œæˆ")
    
    # ==================== Step 6: å¼€å§‹è®­ç»ƒ ====================
    print(f"\n{'='*60}")
    print("æ­¥éª¤ 6/6: å¼€å§‹è®­ç»ƒ")
    print(f"{'='*60}\n")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯æ¢å¤çš„æ£€æŸ¥ç‚¹
    checkpoint = None
    if os.path.exists(args.output_dir):
        checkpoints = [
            d for d in os.listdir(args.output_dir) 
            if d.startswith("checkpoint-")
        ]
        if checkpoints:
            # æ‰¾åˆ°æœ€æ–°çš„æ£€æŸ¥ç‚¹
            latest = max(checkpoints, key=lambda x: int(x.split("-")[-1]))
            checkpoint = os.path.join(args.output_dir, latest)
            print(f"âœ“ å‘ç°æ£€æŸ¥ç‚¹ï¼Œå°†ä» {checkpoint} æ¢å¤è®­ç»ƒ\n")
    
    # å¼€å§‹è®­ç»ƒ
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
    
    # ==================== ä¿å­˜æœ€ç»ˆæ¨¡å‹ ====================
    final_dir = os.path.join(args.output_dir, "final_adapter")
    trainer.save_model(final_dir)
    
    # ä¿å­˜è®­ç»ƒæŒ‡æ ‡
    metrics = train_result.metrics
    trainer.log_metrics("train", metrics)
    trainer.save_metrics("train", metrics)
    
    # å®Œæˆæç¤º
    print(f"\n{'='*60}")
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"{'='*60}")
    print(f"âœ“ æœ€ç»ˆé€‚é…å™¨ä¿å­˜è‡³: {final_dir}")
    print(f"âœ“ è®­ç»ƒæŸå¤±: {metrics.get('train_loss', 'N/A'):.4f}")
    print(f"âœ“ æ€»è®­ç»ƒæ­¥æ•°: {metrics.get('train_steps', 'N/A')}")
    print(f"{'='*60}\n")


# ============================================================================
# ç¨‹åºå…¥å£
# ============================================================================

if __name__ == "__main__":
    train()